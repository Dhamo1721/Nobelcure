import numpy as np
import pandas as pd
file_path = r"C:\Users\Dhamo\Documents\crop prediction\crop recommendation\croprecommandation.csv"
data = pd.read_csv(file_path)
data = data[:10000]
print(data.head())
    N   P   K  temperature   humidity        ph    rainfall label
0  90  42  43    20.879744  82.002744  6.502985  202.935536  rice
1  85  58  41    21.770462  80.319644  7.038096  226.655537  rice
2  60  55  44    23.004459  82.320763  7.840207  263.964248  rice
3  74  35  40    26.491096  80.158363  6.980401  242.864034  rice
4  78  42  42    20.130175  81.604873  7.628473  262.717340  rice
data.info()
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2200 entries, 0 to 2199
Data columns (total 8 columns):
 #   Column       Non-Null Count  Dtype  
---  ------       --------------  -----  
 0   N            2200 non-null   int64  
 1   P            2200 non-null   int64  
 2   K            2200 non-null   int64  
 3   temperature  2200 non-null   float64
 4   humidity     2200 non-null   float64
 5   ph           2200 non-null   float64
 6   rainfall     2200 non-null   float64
 7   label        2200 non-null   object 
dtypes: float64(4), int64(3), object(1)
memory usage: 137.6+ KB
data = data.dropna()
data.info()
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2200 entries, 0 to 2199
Data columns (total 8 columns):
 #   Column       Non-Null Count  Dtype  
---  ------       --------------  -----  
 0   N            2200 non-null   int64  
 1   P            2200 non-null   int64  
 2   K            2200 non-null   int64  
 3   temperature  2200 non-null   float64
 4   humidity     2200 non-null   float64
 5   ph           2200 non-null   float64
 6   rainfall     2200 non-null   float64
 7   label        2200 non-null   object 
dtypes: float64(4), int64(3), object(1)
memory usage: 137.6+ KB
data.info()
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2200 entries, 0 to 2199
Data columns (total 8 columns):
 #   Column       Non-Null Count  Dtype  
---  ------       --------------  -----  
 0   N            2200 non-null   int64  
 1   P            2200 non-null   int64  
 2   K            2200 non-null   int64  
 3   temperature  2200 non-null   float64
 4   humidity     2200 non-null   float64
 5   ph           2200 non-null   float64
 6   rainfall     2200 non-null   float64
 7   label        2200 non-null   object 
dtypes: float64(4), int64(3), object(1)
memory usage: 137.6+ KB
data.describe()
N	P	K	temperature	humidity	ph	rainfall
count	2200.000000	2200.000000	2200.000000	2200.000000	2200.000000	2200.000000	2200.000000
mean	50.551818	53.362727	48.149091	25.616244	71.481779	6.469480	103.463655
std	36.917334	32.985883	50.647931	5.063749	22.263812	0.773938	54.958389
min	0.000000	5.000000	5.000000	8.825675	14.258040	3.504752	20.211267
25%	21.000000	28.000000	20.000000	22.769375	60.261953	5.971693	64.551686
50%	37.000000	51.000000	32.000000	25.598693	80.473146	6.425045	94.867624
75%	84.250000	68.000000	49.000000	28.561654	89.948771	6.923643	124.267508
max	140.000000	145.000000	205.000000	43.675493	99.981876	9.935091	298.560117
data.hist()
array([[<AxesSubplot:title={'center':'N'}>,
        <AxesSubplot:title={'center':'P'}>,
        <AxesSubplot:title={'center':'K'}>],
       [<AxesSubplot:title={'center':'temperature'}>,
        <AxesSubplot:title={'center':'humidity'}>,
        <AxesSubplot:title={'center':'ph'}>],
       [<AxesSubplot:title={'center':'rainfall'}>, <AxesSubplot:>,
        <AxesSubplot:>]], dtype=object)

pip install scikit-learn
Requirement already satisfied: scikit-learn in c:\users\dhamo\anaconda3\lib\site-packages (1.1.1)
Requirement already satisfied: threadpoolctl>=2.0.0 in c:\users\dhamo\anaconda3\lib\site-packages (from scikit-learn) (2.2.0)
Requirement already satisfied: scipy>=1.3.2 in c:\users\dhamo\anaconda3\lib\site-packages (from scikit-learn) (1.7.3)
Requirement already satisfied: joblib>=1.0.0 in c:\users\dhamo\anaconda3\lib\site-packages (from scikit-learn) (1.1.0)
Requirement already satisfied: numpy>=1.17.3 in c:\users\dhamo\anaconda3\lib\site-packages (from scikit-learn) (1.21.6)
Note: you may need to restart the kernel to use updated packages.
WARNING: Error parsing requirements for keras: [Errno 2] No such file or directory: 'c:\\users\\dhamo\\anaconda3\\lib\\site-packages\\keras-2.9.0.dist-info\\METADATA'
from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()

State_Name = fit_transform(State_Name)
District_Name = le.fit_transform(data.District_Name)
Crop_Year = le.fit_transform(data.Crop_Year)
crop = le.fit_transform(data.Crop)
Season = le.fit_transform(data.Season)
data['State_Name'] = State_Name
data['District_Name'] = District_Name
data['Crop_Year'] = Crop_Year
data['Crop'] = crop
data['Season']  = Season
---------------------------------------------------------------------------
NameError                                 Traceback (most recent call last)
Input In [25], in <cell line: 4>()
      1 from sklearn.preprocessing import LabelEncoder
      2 le = LabelEncoder()
----> 4 State_Name = fit_transform(State_Name)
      5 District_Name = le.fit_transform(data.District_Name)
      6 Crop_Year = le.fit_transform(data.Crop_Year)

NameError: name 'fit_transform' is not defined
data.head()
State_Name	District_Name	Crop_Year	Season	Crop	Temperature	humidity	soil moisture	area	Production
0	0	9	3	1	0	36	35	45	1254.0	2000.0
1	0	9	3	1	41	37	40	46	2.0	1.0
2	0	9	3	1	51	36	41	50	102.0	321.0
3	0	9	3	3	3	37	42	55	176.0	641.0
4	0	9	3	3	10	36	40	54	720.0	165.0
from sklearn.model_selection import train_test_split
#from sklearn.cross_validation import train_test_split
X = data.iloc[:,:-1]
y = data.iloc[:,-1]
X_train,X_test,Y_train,Y_test = train_test_split(X,y,test_size=0.2,random_state=100)
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import roc_auc_score , classification_report, mean_squared_error, r2_score
forest = RandomForestRegressor(n_estimators=1000, 
                               criterion='mse', 
                               random_state=1, 
                               n_jobs=-1)
forest.fit(X_train, Y_train)
y_train_pred = forest.predict(X_train)
y_test_pred = forest.predict(X_test)

print('MSE train: %.3f, test: %.3f' % (
        mean_squared_error(Y_train, y_train_pred),
        mean_squared_error(Y_test, y_test_pred)))
print('R^2 train: %.3f, test: %.3f' % (
        r2_score(Y_train, y_train_pred),
        r2_score(Y_test, y_test_pred)))
C:\Users\Dhamo\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(
MSE train: 7023640414606.193, test: 43311638797231.828
R^2 train: 0.990, test: 0.958
print(forest.score(X_test,Y_test))
0.9581139626404562
forest.predict(X_test)
array([6.39245193e+05, 2.97393199e+05, 8.57097100e+03, ...,
       8.04864000e+01, 1.12687002e+05, 7.71037200e+03])
X_test
State_Name	District_Name	Crop_Year	Season	Crop	Temperature	humidity	soil moisture	area
6880	1	13	15	1	58	36	40	54	9896.0
9780	1	17	16	2	30	34	55	62	50712.0
6584	1	13	6	3	40	34	45	52	1660.0
2073	1	4	7	1	2	37	42	55	1840.0
123	0	10	13	2	60	34	55	62	109.0
...	...	...	...	...	...	...	...	...	...
3903	1	6	15	2	39	34	55	62	28.0
7686	1	14	17	2	24	36	35	45	4852.0
5839	1	11	7	1	35	35	50	59	126.0
2068	1	4	6	3	61	35	50	59	18768.0
2746	1	5	5	3	40	37	40	46	1359.0
1987 rows Ã— 9 columns

forest.predict([[1,5,5,3,40,37,40,46,1359.0]])
C:\Users\Dhamo\anaconda3\lib\site-packages\sklearn\base.py:450: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(
array([7710.372])
state = input('enter state:')
district = input('enter district:')
year = input('enter year:')
season = input('enter season:')
crop = input('enter crop:')
Temperature = input('enter Temperature')
humidity= input('enter humidity')
soilmoisture= input('enter soilmoisture')
area = input('enter area')

out_1 = forest.predict([[float(state),
       float(district),
       float(year),
       float(season),
       float(crop),
       float(Temperature),
       float(humidity),
       float(soilmoisture),
       float(area)]])
print(out_1)
print('crop yield Production:',out_1)
enter state:Andhra Pradesh
enter district:ANANTAPUR
enter year:2000
enter season:Rabi       
enter crop:Linseed
enter Temperature37
enter humidity42
enter soilmoisture55
enter area8
---------------------------------------------------------------------------
NameError                                 Traceback (most recent call last)
Input In [5], in <cell line: 11>()
      8 soilmoisture= input('enter soilmoisture')
      9 area = input('enter area')
---> 11 out_1 = forest.predict([[float(state),
     12        float(district),
     13        float(year),
     14        float(season),
     15        float(crop),
     16        float(Temperature),
     17        float(humidity),
     18        float(soilmoisture),
     19        float(area)]])
     20 print(out_1)
     21 print('crop yield Production:',out_1)

NameError: name 'forest' is not defined
data_1 = pd.read_csv(r"C:\Users\Dhamo\Documents\crop prediction\crop recommendation\crop fertilizer.csv")
data_1
n	p	k	amt of n	amt of p	amt of k
0	3 5 6 64 50 60	NaN	NaN	NaN	NaN	NaN
1	1 4 2 40 46 30	NaN	NaN	NaN	NaN	NaN
2	5 1 5 93 16 32	NaN	NaN	NaN	NaN	NaN
3	3 1 3 63 20 39	NaN	NaN	NaN	NaN	NaN
4	4 6 6 87 37 39	NaN	NaN	NaN	NaN	NaN
5	2 1 1 65 19 32	NaN	NaN	NaN	NaN	NaN
n = data_1.iloc[:,0:1]
p = data_1.iloc[:,1:2]
k = data_1.iloc[:,2:3]
amt_n = data_1.iloc[:,3:4]
amt_p = data_1.iloc[:,4:5]
amt_k = data_1.iloc[:,5:6]
X_n_train , X_n_test , y_n_train , y_n_test = train_test_split(n,amt_n,test_size=0.2,random_state=100)
X_p_train , X_p_test , y_p_train , y_p_test = train_test_split(p,amt_p,test_size=0.2,random_state=100)
X_k_train , X_k_test , y_k_train , y_k_test = train_test_split(k,amt_k,test_size=0.2,random_state=100)
from sklearn.neural_network import MLPRegressor
clf_n = MLPRegressor(solver='lbfgs', alpha=1e-5,hidden_layer_sizes=(5, 2), random_state=1)
clf_n.fit(X_n_train, y_n_train)
y_n_pred = clf_n.predict(y_n_test)
clf_n.score(y_n_test,y_n_pred)
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
Input In [69], in <cell line: 3>()
      1 from sklearn.neural_network import MLPRegressor
      2 clf_n = MLPRegressor(solver='lbfgs', alpha=1e-5,hidden_layer_sizes=(5, 2), random_state=1)
----> 3 clf_n.fit(X_n_train, y_n_train)
      4 y_n_pred = clf_n.predict(y_n_test)
      5 clf_n.score(y_n_test,y_n_pred)

File ~\anaconda3\lib\site-packages\sklearn\neural_network\_multilayer_perceptron.py:752, in BaseMultilayerPerceptron.fit(self, X, y)
    735 def fit(self, X, y):
    736     """Fit the model to data matrix X and target(s) y.
    737 
    738     Parameters
   (...)
    750         Returns a trained MLP model.
    751     """
--> 752     return self._fit(X, y, incremental=False)

File ~\anaconda3\lib\site-packages\sklearn\neural_network\_multilayer_perceptron.py:393, in BaseMultilayerPerceptron._fit(self, X, y, incremental)
    386     raise ValueError(
    387         "hidden_layer_sizes must be > 0, got %s." % hidden_layer_sizes
    388     )
    389 first_pass = not hasattr(self, "coefs_") or (
    390     not self.warm_start and not incremental
    391 )
--> 393 X, y = self._validate_input(X, y, incremental, reset=first_pass)
    395 n_samples, n_features = X.shape
    397 # Ensure y is 2D

File ~\anaconda3\lib\site-packages\sklearn\neural_network\_multilayer_perceptron.py:1589, in MLPRegressor._validate_input(self, X, y, incremental, reset)
   1588 def _validate_input(self, X, y, incremental, reset):
-> 1589     X, y = self._validate_data(
   1590         X,
   1591         y,
   1592         accept_sparse=["csr", "csc"],
   1593         multi_output=True,
   1594         y_numeric=True,
   1595         dtype=(np.float64, np.float32),
   1596         reset=reset,
   1597     )
   1598     if y.ndim == 2 and y.shape[1] == 1:
   1599         y = column_or_1d(y, warn=True)

File ~\anaconda3\lib\site-packages\sklearn\base.py:581, in BaseEstimator._validate_data(self, X, y, reset, validate_separately, **check_params)
    579         y = check_array(y, **check_y_params)
    580     else:
--> 581         X, y = check_X_y(X, y, **check_params)
    582     out = X, y
    584 if not no_val_X and check_params.get("ensure_2d", True):

File ~\anaconda3\lib\site-packages\sklearn\utils\validation.py:964, in check_X_y(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)
    961 if y is None:
    962     raise ValueError("y cannot be None")
--> 964 X = check_array(
    965     X,
    966     accept_sparse=accept_sparse,
    967     accept_large_sparse=accept_large_sparse,
    968     dtype=dtype,
    969     order=order,
    970     copy=copy,
    971     force_all_finite=force_all_finite,
    972     ensure_2d=ensure_2d,
    973     allow_nd=allow_nd,
    974     ensure_min_samples=ensure_min_samples,
    975     ensure_min_features=ensure_min_features,
    976     estimator=estimator,
    977 )
    979 y = _check_y(y, multi_output=multi_output, y_numeric=y_numeric)
    981 check_consistent_length(X, y)

File ~\anaconda3\lib\site-packages\sklearn\utils\validation.py:746, in check_array(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)
    744         array = array.astype(dtype, casting="unsafe", copy=False)
    745     else:
--> 746         array = np.asarray(array, order=order, dtype=dtype)
    747 except ComplexWarning as complex_warning:
    748     raise ValueError(
    749         "Complex data not supported\n{}\n".format(array)
    750     ) from complex_warning

File ~\anaconda3\lib\site-packages\pandas\core\generic.py:2064, in NDFrame.__array__(self, dtype)
   2063 def __array__(self, dtype: npt.DTypeLike | None = None) -> np.ndarray:
-> 2064     return np.asarray(self._values, dtype=dtype)

ValueError: could not convert string to float: '4 6 6 87 37 39'
clf_p = MLPRegressor(solver='lbfgs', alpha=1e-5,hidden_layer_sizes=(5, 2), random_state=1)
clf_p.fit(X_p_train, y_p_train)
y_p_pred = clf_n.predict(y_p_test)
clf_p.score(y_p_test,y_p_pred)
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
Input In [70], in <cell line: 2>()
      1 clf_p = MLPRegressor(solver='lbfgs', alpha=1e-5,hidden_layer_sizes=(5, 2), random_state=1)
----> 2 clf_p.fit(X_p_train, y_p_train)
      3 y_p_pred = clf_n.predict(y_p_test)
      4 clf_p.score(y_p_test,y_p_pred)

File ~\anaconda3\lib\site-packages\sklearn\neural_network\_multilayer_perceptron.py:752, in BaseMultilayerPerceptron.fit(self, X, y)
    735 def fit(self, X, y):
    736     """Fit the model to data matrix X and target(s) y.
    737 
    738     Parameters
   (...)
    750         Returns a trained MLP model.
    751     """
--> 752     return self._fit(X, y, incremental=False)

File ~\anaconda3\lib\site-packages\sklearn\neural_network\_multilayer_perceptron.py:393, in BaseMultilayerPerceptron._fit(self, X, y, incremental)
    386     raise ValueError(
    387         "hidden_layer_sizes must be > 0, got %s." % hidden_layer_sizes
    388     )
    389 first_pass = not hasattr(self, "coefs_") or (
    390     not self.warm_start and not incremental
    391 )
--> 393 X, y = self._validate_input(X, y, incremental, reset=first_pass)
    395 n_samples, n_features = X.shape
    397 # Ensure y is 2D

File ~\anaconda3\lib\site-packages\sklearn\neural_network\_multilayer_perceptron.py:1589, in MLPRegressor._validate_input(self, X, y, incremental, reset)
   1588 def _validate_input(self, X, y, incremental, reset):
-> 1589     X, y = self._validate_data(
   1590         X,
   1591         y,
   1592         accept_sparse=["csr", "csc"],
   1593         multi_output=True,
   1594         y_numeric=True,
   1595         dtype=(np.float64, np.float32),
   1596         reset=reset,
   1597     )
   1598     if y.ndim == 2 and y.shape[1] == 1:
   1599         y = column_or_1d(y, warn=True)

File ~\anaconda3\lib\site-packages\sklearn\base.py:581, in BaseEstimator._validate_data(self, X, y, reset, validate_separately, **check_params)
    579         y = check_array(y, **check_y_params)
    580     else:
--> 581         X, y = check_X_y(X, y, **check_params)
    582     out = X, y
    584 if not no_val_X and check_params.get("ensure_2d", True):

File ~\anaconda3\lib\site-packages\sklearn\utils\validation.py:964, in check_X_y(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)
    961 if y is None:
    962     raise ValueError("y cannot be None")
--> 964 X = check_array(
    965     X,
    966     accept_sparse=accept_sparse,
    967     accept_large_sparse=accept_large_sparse,
    968     dtype=dtype,
    969     order=order,
    970     copy=copy,
    971     force_all_finite=force_all_finite,
    972     ensure_2d=ensure_2d,
    973     allow_nd=allow_nd,
    974     ensure_min_samples=ensure_min_samples,
    975     ensure_min_features=ensure_min_features,
    976     estimator=estimator,
    977 )
    979 y = _check_y(y, multi_output=multi_output, y_numeric=y_numeric)
    981 check_consistent_length(X, y)

File ~\anaconda3\lib\site-packages\sklearn\utils\validation.py:800, in check_array(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)
    794         raise ValueError(
    795             "Found array with dim %d. %s expected <= 2."
    796             % (array.ndim, estimator_name)
    797         )
    799     if force_all_finite:
--> 800         _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
    802 if ensure_min_samples > 0:
    803     n_samples = _num_samples(array)

File ~\anaconda3\lib\site-packages\sklearn\utils\validation.py:114, in _assert_all_finite(X, allow_nan, msg_dtype)
    107     if (
    108         allow_nan
    109         and np.isinf(X).any()
    110         or not allow_nan
    111         and not np.isfinite(X).all()
    112     ):
    113         type_err = "infinity" if allow_nan else "NaN, infinity"
--> 114         raise ValueError(
    115             msg_err.format(
    116                 type_err, msg_dtype if msg_dtype is not None else X.dtype
    117             )
    118         )
    119 # for object dtype data, we only check for NaNs (GH-13254)
    120 elif X.dtype == np.dtype("object") and not allow_nan:

ValueError: Input contains NaN, infinity or a value too large for dtype('float64').
clf_k = MLPRegressor(solver='lbfgs', alpha=1e-5,hidden_layer_sizes=(5, 2), random_state=1)
clf_k.fit(X_p_train, y_k_train)
y_k_pred = clf_n.predict(y_k_test)
clf_k.score(y_k_test,y_k_pred)
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
Input In [71], in <cell line: 2>()
      1 clf_k = MLPRegressor(solver='lbfgs', alpha=1e-5,hidden_layer_sizes=(5, 2), random_state=1)
----> 2 clf_k.fit(X_p_train, y_k_train)
      3 y_k_pred = clf_n.predict(y_k_test)
      4 clf_k.score(y_k_test,y_k_pred)

File ~\anaconda3\lib\site-packages\sklearn\neural_network\_multilayer_perceptron.py:752, in BaseMultilayerPerceptron.fit(self, X, y)
    735 def fit(self, X, y):
    736     """Fit the model to data matrix X and target(s) y.
    737 
    738     Parameters
   (...)
    750         Returns a trained MLP model.
    751     """
--> 752     return self._fit(X, y, incremental=False)

File ~\anaconda3\lib\site-packages\sklearn\neural_network\_multilayer_perceptron.py:393, in BaseMultilayerPerceptron._fit(self, X, y, incremental)
    386     raise ValueError(
    387         "hidden_layer_sizes must be > 0, got %s." % hidden_layer_sizes
    388     )
    389 first_pass = not hasattr(self, "coefs_") or (
    390     not self.warm_start and not incremental
    391 )
--> 393 X, y = self._validate_input(X, y, incremental, reset=first_pass)
    395 n_samples, n_features = X.shape
    397 # Ensure y is 2D

File ~\anaconda3\lib\site-packages\sklearn\neural_network\_multilayer_perceptron.py:1589, in MLPRegressor._validate_input(self, X, y, incremental, reset)
   1588 def _validate_input(self, X, y, incremental, reset):
-> 1589     X, y = self._validate_data(
   1590         X,
   1591         y,
   1592         accept_sparse=["csr", "csc"],
   1593         multi_output=True,
   1594         y_numeric=True,
   1595         dtype=(np.float64, np.float32),
   1596         reset=reset,
   1597     )
   1598     if y.ndim == 2 and y.shape[1] == 1:
   1599         y = column_or_1d(y, warn=True)

File ~\anaconda3\lib\site-packages\sklearn\base.py:581, in BaseEstimator._validate_data(self, X, y, reset, validate_separately, **check_params)
    579         y = check_array(y, **check_y_params)
    580     else:
--> 581         X, y = check_X_y(X, y, **check_params)
    582     out = X, y
    584 if not no_val_X and check_params.get("ensure_2d", True):

File ~\anaconda3\lib\site-packages\sklearn\utils\validation.py:964, in check_X_y(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)
    961 if y is None:
    962     raise ValueError("y cannot be None")
--> 964 X = check_array(
    965     X,
    966     accept_sparse=accept_sparse,
    967     accept_large_sparse=accept_large_sparse,
    968     dtype=dtype,
    969     order=order,
    970     copy=copy,
    971     force_all_finite=force_all_finite,
    972     ensure_2d=ensure_2d,
    973     allow_nd=allow_nd,
    974     ensure_min_samples=ensure_min_samples,
    975     ensure_min_features=ensure_min_features,
    976     estimator=estimator,
    977 )
    979 y = _check_y(y, multi_output=multi_output, y_numeric=y_numeric)
    981 check_consistent_length(X, y)

File ~\anaconda3\lib\site-packages\sklearn\utils\validation.py:800, in check_array(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)
    794         raise ValueError(
    795             "Found array with dim %d. %s expected <= 2."
    796             % (array.ndim, estimator_name)
    797         )
    799     if force_all_finite:
--> 800         _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
    802 if ensure_min_samples > 0:
    803     n_samples = _num_samples(array)

File ~\anaconda3\lib\site-packages\sklearn\utils\validation.py:114, in _assert_all_finite(X, allow_nan, msg_dtype)
    107     if (
    108         allow_nan
    109         and np.isinf(X).any()
    110         or not allow_nan
    111         and not np.isfinite(X).all()
    112     ):
    113         type_err = "infinity" if allow_nan else "NaN, infinity"
--> 114         raise ValueError(
    115             msg_err.format(
    116                 type_err, msg_dtype if msg_dtype is not None else X.dtype
    117             )
    118         )
    119 # for object dtype data, we only check for NaNs (GH-13254)
    120 elif X.dtype == np.dtype("object") and not allow_nan:

ValueError: Input contains NaN, infinity or a value too large for dtype('float64').
n_i = float(input('enter nitrogen:'))
p_i = float(input('enter posporus:'))
k_i = float(input('enter pottasium:'))
p_n = clf_n.predict([[n_i]])
p_p = clf_p.predict([[p_i]])
p_k = clf_k.predict([[k_i]])
print('Amount of nitrogen Fertizer:',p_n)
print('Amount of posporus Fertizer:',p_p)
print('Amount of nitrogen Fertizer:',p_k)
enter nitrogen:43
enter posporus:77
enter pottasium:87
C:\Users\Dhamo\anaconda3\lib\site-packages\sklearn\base.py:450: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names
  warnings.warn(
---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
Input In [72], in <cell line: 4>()
      2 p_i = float(input('enter posporus:'))
      3 k_i = float(input('enter pottasium:'))
----> 4 p_n = clf_n.predict([[n_i]])
      5 p_p = clf_p.predict([[p_i]])
      6 p_k = clf_k.predict([[k_i]])

File ~\anaconda3\lib\site-packages\sklearn\neural_network\_multilayer_perceptron.py:1583, in MLPRegressor.predict(self, X)
   1570 """Predict using the multi-layer perceptron model.
   1571 
   1572 Parameters
   (...)
   1580     The predicted values.
   1581 """
   1582 check_is_fitted(self)
-> 1583 y_pred = self._forward_pass_fast(X)
   1584 if y_pred.shape[1] == 1:
   1585     return y_pred.ravel()

File ~\anaconda3\lib\site-packages\sklearn\neural_network\_multilayer_perceptron.py:166, in BaseMultilayerPerceptron._forward_pass_fast(self, X)
    164 # Forward propagate
    165 hidden_activation = ACTIVATIONS[self.activation]
--> 166 for i in range(self.n_layers_ - 1):
    167     activation = safe_sparse_dot(activation, self.coefs_[i])
    168     activation += self.intercepts_[i]

AttributeError: 'MLPRegressor' object has no attribute 'n_layers_'
from tkinter import *
from tkinter import ttk

root = Tk()
root.title('Crop Yield and fertilizer Prediction System')
root.geometry('850x650')
root.configure(background="purple2")
var = StringVar()
label = Label( root, textvariable = var,font=('arial',20,'bold'),bd=20,background="purple2")
var.set('Crop Yield and fertilizer Prediction System')
label.grid(row=0,columnspan=6)



label_1 = ttk.Label(root, text ='state',font=("Helvetica", 16),background="Purple3")
label_1.grid(row=11,column=0)
    
Entry_1= Entry(root)
Entry_1.grid(row=11,column=1)

label_2 = ttk.Label(root, text ='district',font=("Helvetica", 16),background="Purple3")
label_2.grid(row=12,column=0)
    
Entry_2 = Entry(root)
Entry_2.grid(row=12,column=1)
    
    
label_3 = ttk.Label(root, text ='year',font=("Helvetica", 16),background="Purple3")
label_3.grid(row=13,column=0)
    
Entry_3 = Entry(root)
Entry_3.grid(row=13,column=1)

label_4 = ttk.Label(root, text ='season',font=("Helvetica", 16),background="Purple3")
label_4.grid(row=14,column=0)
    
Entry_4= Entry(root)
Entry_4.grid(row=14,column=1)

label_5 = ttk.Label(root, text ='crop',font=("Helvetica", 16),background="Purple3")
label_5.grid(row=15,column=0)
    
Entry_6 = Entry(root)
Entry_6.grid(row=15,column=1)
    
    
label_6 = ttk.Label(root, text ='Temperature',font=("Helvetica", 16),background="Purple3")
label_6.grid(row=16,column=0)
    
Entry_6 = Entry(root)
Entry_6.grid(row=16,column=1)

label_7 = ttk.Label(root, text ='humidity',font=("Helvetica", 16),background="Purple3")
label_7.grid(row=17,column=0)
    
Entry_7= Entry(root)
Entry_7.grid(row=17,column=1)

label_8 = ttk.Label(root, text ='soilmoisture',font=("Helvetica", 16),background="Purple3")
label_8.grid(row=18,column=0)

Entry_8 = Entry(root)
Entry_8.grid(row=18,column=1)
    
    
label_9 = ttk.Label(root, text ='area',font=("Helvetica", 16),background="Purple3")
label_9.grid(row=19,column=0)
    
Entry_9 = Entry(root)
Entry_9.grid(row=19,column=1)


def predict():
    state = Entry_1.get()
    district = Entry_2.get()
    year = Entry_3.get()
    season = Entry_4.get()
    crop = Entry_5.get()
    Temperature = Entry_6.get()
    humidity = Entry_7.get()
    soilmoisture = Entry_8.get()
    area = Entry_9.get()
    out = forest.predict([[float(state),
       float(district),
       float(year),
       float(season),
       float(crop),
       float(Temperature),
       float(humidity),
       float(soilmoisture),
       float(area)]])
    
    output.delete(0,END)
    output.insert(0,out)
   
        

b1 = Button(root, text = 'predict',font=("Helvetica", 16),background="Purple3",command = predict)
b1.grid(row=14,column=0)
    

output = Entry(root)
output.grid(row=20,column=1)
    
root.mainloop()
